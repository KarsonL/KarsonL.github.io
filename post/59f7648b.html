<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>AMC：AutoML for Model Compression and Acceleration on Mobile Devices 论文笔记 | Karson.L</title><meta name="keywords" content="AutoML,pruning,model compression,deep learning"><meta name="author" content="Karson.L"><meta name="copyright" content="Karson.L"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="这篇文章是MIT韩松老师组提出的一种模型压缩方法，其核心思想是使用强化学习方法自动得到神经网络各层的剪枝率，然后对神经网络进行剪枝，从而压缩模型，使其能在移动设备上运行。">
<meta property="og:type" content="article">
<meta property="og:title" content="AMC：AutoML for Model Compression and Acceleration on Mobile Devices 论文笔记">
<meta property="og:url" content="https://karsonl.github.io/post/59f7648b.html">
<meta property="og:site_name" content="Karson.L">
<meta property="og:description" content="这篇文章是MIT韩松老师组提出的一种模型压缩方法，其核心思想是使用强化学习方法自动得到神经网络各层的剪枝率，然后对神经网络进行剪枝，从而压缩模型，使其能在移动设备上运行。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201224160209513.png">
<meta property="article:published_time" content="2020-12-24T13:19:17.000Z">
<meta property="article:modified_time" content="2022-06-20T07:24:45.390Z">
<meta property="article:author" content="Karson.L">
<meta property="article:tag" content="AutoML">
<meta property="article:tag" content="pruning">
<meta property="article:tag" content="model compression">
<meta property="article:tag" content="deep learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20201224160209513.png"><link rel="shortcut icon" href="/./imgs/author/jide.jpg"><link rel="canonical" href="https://karsonl.github.io/post/59f7648b"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'AMC：AutoML for Model Compression and Acceleration on Mobile Devices 论文笔记',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-06-20 15:24:45'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./imgs/author/jide.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">10</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://img-blog.csdnimg.cn/20201224160209513.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Karson.L</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">AMC：AutoML for Model Compression and Acceleration on Mobile Devices 论文笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2020-12-24T13:19:17.000Z" title="发表于 2020-12-24 21:19:17">2020-12-24</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/model-compression/">model compression</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="AMC：AutoML for Model Compression and Acceleration on Mobile Devices 论文笔记"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p>原文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1802.03494.pdf">https://arxiv.org/pdf/1802.03494.pdf</a><br>源码链接：<a target="_blank" rel="noopener" href="https://github.com/mit-han-lab/amc">https://github.com/mit-han-lab/amc</a><br>其他代码实现：<a target="_blank" rel="noopener" href="https://github.com/zzzxxxttt/pytorch_AMC">https://github.com/zzzxxxttt/pytorch_AMC</a></p>
<p>该博文转载自我的CSDN博客：<a target="_blank" rel="noopener" href="https://blog.csdn.net/yellow_violet/article/details/111634332?spm=1001.2014.3001.5502">AMC：AutoML for Model Compression and Acceleration on Mobile Devices 论文笔记_Karson.L的博客-CSDN博客</a></p>
</blockquote>
<h1 id="一、核心思想"><a href="#一、核心思想" class="headerlink" title="一、核心思想"></a>一、核心思想</h1><p>这篇文章是MIT韩松老师组提出的一种模型压缩方法，其核心思想是<strong>使用强化学习方法自动得到神经网络各层的剪枝率，然后对神经网络进行剪枝，从而压缩模型，使其能在移动设备上运行。</strong></p>
<p>里面涉及到了卷积神经网络剪枝和强化学习的知识。如果没有基础的同学可能需要去了解一下：</p>
<ol>
<li>Pruning filters for efficient convnets</li>
<li>Channel pruning for accelerating very deep neural networks</li>
<li>还有强化学习里面的DDPG，这个是这篇文章的<strong>重点</strong>。</li>
<li>还有剪枝里面的细粒度剪枝和粗粒度剪枝等。</li>
<li>补充：还有soft pruning的知识也需要。看代码的时候需要用到。</li>
</ol>
<h1 id="二、问题分析"><a href="#二、问题分析" class="headerlink" title="二、问题分析"></a>二、问题分析</h1><p><img src="https://img-blog.csdnimg.cn/20201224155320376.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3llbGxvd192aW9sZXQ=,size_16,color_FFFFFF,t_70" alt=""><br>前面基础那里给了几个经典的网络剪枝方法，filter prune、channel pruning ，这些方法在网络模型压缩方面都得到了不错的效果。</p>
<p>但是这些方法都存在一个问题就是，需要<strong>人工去设定好每层的剪枝率，或者直接就设定每层的剪枝率是一样的。</strong></p>
<p>然而，我们可以从这张图看出。这张图是fliter pruned 文章里的图。可以看出， 不同的层对不同的的剪枝率的敏感性是不一样的。虚线那些，冗余多，剪枝率达到60% 时性能也没下降多少。而实线这些，剪一点点，性能也下降很严重。所以说，<strong>每层应该要设置不一样的剪枝率。</strong></p>
<p>在那篇论文里，作者虽然设置了每层不一样的剪枝率的。但是他是通过这样一层一层的试验得到的结果。这样显然是很耗费时间的。特别是对于现在越来越深的网络，动不动就上百层的，每一层不同剪枝率一个一个设，那是相当耗费时间的且不合理的。</p>
<p>所以我们希望找到一种方法来<strong>自动的确定每一层的剪枝率。</strong></p>
<p>而且，还有个问题就是，<strong>网络不同层之间并不是完全独立的，他们是相互依赖的</strong>。每层单独剪的好，但是组合在一起并不一定是最好的。我们要得到的应该是一个最优的组合。</p>
<p>所以，如何解决以上问题，<strong>自动的得到每一层的剪枝率，并考虑整体的关系</strong>，就是这篇文章的出发点了。</p>
<h1 id="三、方法框架"><a href="#三、方法框架" class="headerlink" title="三、方法框架"></a>三、方法框架</h1><p><img src="https://img-blog.csdnimg.cn/20201224160209513.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3llbGxvd192aW9sZXQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>这篇文章使用的自动搜索方法就是强化学习中的<strong>DDPG</strong>。文章将要剪枝的网络建模成环境，网络的结构数据就是环境的状态，然后DDPG训练Agent与环境进行交互，根据网络的状态输出每一层的剪枝率。网络在每层剪枝后会更新状态转移到下一层，并给出奖励给Agent，Agent根据奖励进行更新。</p>
<p>但是，看起来好像挺简单。但是要想强化学习能完成特定的任务，只知道用哪个方法还不行，最重要的还是怎么去建模。或说，怎么设计这个Agent里的元素，即强化学习里的动作、状态、奖励、损失函数等。这些才是最重要的。这些元素没设计好，最终得到的Agent可能不会收敛，无法完成任务。</p>
<p>我觉得这篇文章的<strong>核心就是这些元素的设计。</strong></p>
<h1 id="四、核心设计"><a href="#四、核心设计" class="headerlink" title="四、核心设计"></a>四、核心设计</h1><h2 id="4-1-动作设计"><a href="#4-1-动作设计" class="headerlink" title="4.1 动作设计"></a>4.1 动作设计</h2><p><img src="https://img-blog.csdnimg.cn/20201224161501719.png" alt="在这里插入图片描述"></p>
<p>首先是<strong>动作</strong>的设计。</p>
<p>因为任务是对网络的<strong>剪枝</strong>，所以输出的动作应该就是每层网络的<strong>剪枝率</strong>。所以设置成了<strong>0到1</strong>之间的<strong>连续值</strong>。</p>
<p>之前有用其他搜索算法直接搜索每层的要剪枝的数量的。但是因为每层的通道数是不一样的，所以如果直接输出要剪枝的通道数，则每层的搜索空间是不固定的，每层都要进行筛选，截断，造成不必要的计算，而设置成剪枝率，则每层的动作空间都是固定在0到1的。搜索空间固定，则就不需要其他的计算，搜索起来也会更加有效。</p>
<p><img src="https://img-blog.csdnimg.cn/20201224161531695.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3llbGxvd192aW9sZXQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>文章还和DDPG一样给动作<strong>增加噪声</strong>。使用的<strong>截断的正态分布</strong>，以Actor的输出作为均值，以σ为方差，在0到1内随机取样得到真正的剪枝率。σ是手动设置的，随着训练的进行会不断减小。就像ε-greedy一样，目的就是平衡探索与利用。前期σ大，噪声大，增加探索，防止陷入局部解；后期σ不断减小，减小Agent的探索，使Agent逐渐收敛。</p>
<h2 id="4-2-状态设计"><a href="#4-2-状态设计" class="headerlink" title="4.2 状态设计"></a>4.2 状态设计</h2><p><img src="https://img-blog.csdnimg.cn/20201224161621997.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3llbGxvd192aW9sZXQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>这是文章中的状态，设计的很复杂，包含了11个元素。</p>
<p>虽然复杂，但这个状态其实可以认为包含了两个部分。</p>
<p>首先是前面的这一部分，它包含了当前要剪枝的层的参数信息。层数、输入输出通道数、卷积核大小、步长，输入特征图大小。这些可以让Agent知道当前处于哪一层。</p>
<p>而后面这一部分，则是与浮点运算数FLOPs相关。FLOPs表征的是网络的运算复杂度，一定程度上反映了网络整体的参数量大小或说模型大小。也就是说后面这一部分表示的是网络整体的参数量信息，即与网络整体的剪枝相关。本层的FLOPs、之前被剪掉的FLOPs、之后还要剪的FLOPs，以及上一层的动作，这些都构成了当前整个网络剪枝的全局信息，因此，Agent可以从整体上来考虑当前的剪枝率。</p>
<p>前面也说过，层与层之间不是相互独立的，而是相互影响的。最优的结构应该是要考虑整个网络而不是单层考虑的。这里应该就体现了这样一个思想。</p>
<p>因此，通过这两部分的作用，Agent不仅能知道当前处于哪层，还能知道整体信息，从而做出考虑整体更优的一个决策。</p>
<blockquote>
<p>（留个坑）这里有个疑问，就是虽然状态复杂对Agent有利于做出更优的决策，但是状态空间加大，势必会造成搜索时间加长。而且，这里面的每一个元素也不知道是否都是必要的，特别是前面的部分，如k，stride，因为这些在每一次搜索的过程都是不会变的，似乎对于区分当前处于哪一层不是那么必要。</p>
<p>我本来也想做实验试试，奈何代码能力有限，还没搞好。所以之后等搞出来，再看看。</p>
</blockquote>
<h3 id="4-2-1-状态的计算"><a href="#4-2-1-状态的计算" class="headerlink" title="4.2.1 状态的计算"></a>4.2.1 状态的计算</h3><p>状态前面的部分都是卷积层的参数，在运行的过程中几乎是不会怎么变化的，但是后面的部分，则是与这一次的整个网络的剪枝都是相关的，是会随着剪枝的进行不断变化，所以需要额外的计算。</p>
<ul>
<li><strong>FLOPs的计算</strong><br>首先是FLOPs，也就是浮点运算数，表示的是网络计算中加法和乘法的次数。计算公式如下，具体怎么来的自行推导。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20201224163617210.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3llbGxvd192aW9sZXQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ul>
<li><p><strong>reduce和rest的计算</strong><br>reduce就是之前被剪掉的FLOPs有多少。就是每层被剪了多少。简单的就是将之前的被剪掉的FLOPs加起来。</p>
<div align=center><img  src ="https://img-blog.csdnimg.cn/20201224163926404.png"/></div>

<p>但是文章给出的计算方式并不是这么简单的，作者还考虑了其他。</p>
</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20201224164105709.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3llbGxvd192aW9sZXQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>文章给的算法是对细粒度剪枝的，这里我重写成粗粒度剪枝里的<strong>channel pruning</strong>了，大概流程都是一样的。</p>
<blockquote>
<ol>
<li>首先，Actor生成了一个<strong>动作</strong>，然后进行截断，保证在0,1内。</li>
<li>然后分别<strong>计算整个网络的FLOPs(Fall)和剩下层的FLOPs(Frest)</strong>，从这里，我们也可以的得知rest的计算就是这样的了。</li>
</ol>
 <div align=center><img  src="https://img-blog.csdnimg.cn/20201224164349860.png"/></div>


<ol>
<li><p>然后<strong>计算这一层应该剪去的FLOPs</strong>，其中<strong>alpha</strong>就是事先设定好的一个<strong>全局压缩率</strong>（关于FLOPs的约束）。alpha<em>Fall<br>就是整体网络要压缩多少FLOPs，也就是给定了一个压缩目标。然后，action_max </em> Frest<br>就是将后面的全剪了，Freduce就是之前被剪掉了多少。<br>所以整一个公式的意思就是假设后面全剪了，前面又剪了，那我这层还要剪去多少才能才能达到目标。duty，就是职责的意思，就是这一层至少要完成的一个API。</p>
</li>
<li><p>然后 <strong>Fduty/Ft</strong>就可以得到这一层剪枝率的下界。然后和刚刚Agent得到的剪枝率进行对比，取最大的那个，就才是<strong>最终的剪枝率。</strong></p>
</li>
<li><p>最后，<strong>更新reduce</strong>。将之前的reduce加上这一次被剪掉的FLOPs。因为这里使用的Channel Prune，所以本层通道被剪掉后，上层的对应的滤波器也会被剪掉。所以这里就是Ft+Ft-1。</p>
</li>
</ol>
</blockquote>
<p>这就是状态的设计。真的很佩服作者能想到这样去设计状态。</p>
<h2 id="4-3-奖励函数设计"><a href="#4-3-奖励函数设计" class="headerlink" title="4.3 奖励函数设计"></a>4.3 奖励函数设计</h2><p><img src="https://img-blog.csdnimg.cn/20201224170325353.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3llbGxvd192aW9sZXQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>因为Agent 对网络是逐层剪枝的，而且只有到最后一层剪完后才对网络进行评估。所以之后到最后一层环境才会给出一个奖励。</p>
<p>奖励的设置文章给出了两种情况。</p>
<blockquote>
<ol>
<li><p><strong>资源受限压缩</strong></p>
<p>奖励直接就是<strong>网络的评估误差</strong>。</p>
<p>而所谓<strong>资源受限</strong>，就是指设备运算能力有限。所以在<strong>事先设定好了一个全局的压缩目标</strong>，就是刚刚计算reduce时的那个alpha。也就是对最终的网络进行FLOPs的约束。使得最后得到的网络可以适应设备。</p>
</li>
<li><p><strong>精度保证压缩</strong></p>
<p>这里，是没有给定一个全局压缩率的。而是通过在奖励这里增加约束。也就是这个<strong>log(FLOPs)</strong>。FLOPs越大，那么奖励就是越小。从而对模型大小进行有效的约束。</p>
<p> 至于<strong>精度保证</strong>。因为FLOPs越大，Error损失就越小。也就两者是反比的关系。那么在搜索的过程中，两者就会有一个博弈的过程，到最后两者会达到达到最优的平衡。也就是说，Agent会搜索到在保证Error较小时的最优FLOPs。此时，FLOPs可能会比资源受限的大，但是精度却更高，且有可能几乎和没剪的时候一样。</p>
</li>
</ol>
</blockquote>
<p>状态设计就这样了。</p>
<p> <strong>并没有！！！</strong></p>
<p>文章没有写到，是看了代码之后才发现的。它在每一层剪完之后，环境确实返回的奖励是那个稀疏奖励。但是<strong>在最后一层剪完之后，他会将这一次剪枝的之前所有层的奖励都换成最后网络的评估。</strong></p>
<div align=center><img  src ="https://img-blog.csdnimg.cn/20201224171110980.png"/></div>

<p>确实，我觉得这样才是合理的。因为最后得出来的这个网络并不是只是最后一层的功劳，它是与之前所有层的动作都是相关的，也就是说，每一层的动作对最后网络的性能都是有贡献的。因此，不能就只给最后一层奖励，而其他层奖励就为0，这是不公平的。而将所有层的奖励都设置成一样，我觉得也是体现了一种<strong>从整体考虑</strong>的思想。就是这一个剪枝率组合就对应这个奖励，奖励的好坏代表这个组合的好坏。我们最后得到的也应该是一个最优的组合，一个完整的网络。</p>
<p>所以，通过这样的设置，Agent才会往整体更优的一个网络去搜索。</p>
<h2 id="4-4-损失函数设计"><a href="#4-4-损失函数设计" class="headerlink" title="4.4 损失函数设计"></a>4.4 损失函数设计</h2><p><img src="https://img-blog.csdnimg.cn/20201224171356328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3llbGxvd192aW9sZXQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>损失函数，这里用的就是策略梯度方法里面常用的损失函数。这里的b 是baseline reward，它有减小梯度估计方差的作用，是在Policy Gradient里面的trick，具体可以看李宏毅老师的强化学习视频，或知乎大神的推导（<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/98506549">here</a>）。</p>
<h2 id="4-5-算法流程"><a href="#4-5-算法流程" class="headerlink" title="4.5 算法流程"></a>4.5 算法流程</h2><p><img src="https://img-blog.csdnimg.cn/20201224172058267.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3llbGxvd192aW9sZXQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>这就是全部的DDPG的元素设计了。动作、状态、奖励函数、损失函数。有了这几个东西，就可以搭建Agent，来学习如何自动生成神经网络的剪枝率了。</p>
<h3 id="4-5-1-流程"><a href="#4-5-1-流程" class="headerlink" title="4.5.1 流程"></a>4.5.1 流程</h3><p><img src="https://img-blog.csdnimg.cn/20201224172214781.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3llbGxvd192aW9sZXQ=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<blockquote>
<ol>
<li>在第t层，Actor产生动作at</li>
<li>计算最终的剪枝率at，以及FLOPs、reduce、rest</li>
<li>根据at对本层网络进行剪枝，使用filter pruning或channel pruning</li>
<li>转移到下一个状态st+1，并得到奖励rt</li>
<li>将[st, at, rt, st+1, done]存入列表T中</li>
<li><p>判断是否是最后一层。若否，则t=t+1，回到1；若是，则到7</p>
</li>
<li><p>遍历列表T，将其中的rt换成最终的奖励Rerr</p>
</li>
<li>从T中读取数据放入经验池</li>
<li>从经验池中随机采样一个batch样本</li>
<li>使用batch样本训练DDPG</li>
<li>回到7，直到T中全部层数据转移完毕，则清空T，t=1，回到1</li>
</ol>
</blockquote>
<h1 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h1><ul>
<li><p><strong>提出问题</strong></p>
<p> 以往的神经网络剪枝方法的剪枝率是人工设计的，耗费人力且没有考虑整体信息。</p>
</li>
<li><p><strong>解决问题</strong></p>
<p> 使用强化学习DDPG自动的决定每层神经网络的剪枝率。</p>
</li>
<li><p><strong>如何解决</strong></p>
<p> 通过精心设计DDPG中的动作、状态、奖励函数等元素，使Agent在每一层剪枝时既能获得本层信息，又能得知整体网络信息，从而可以做出有利于整体走向更优的决策，使网络在模型压缩的同时保持较高精度。</p>
</li>
<li><p><strong>结果如何</strong></p>
<p> 能准确剪除网络的冗余部分，有效压缩网络。且在多个数据集上都能表现很好。</p>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://karsonl.github.io">Karson.L</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://karsonl.github.io/post/59f7648b.html">https://karsonl.github.io/post/59f7648b.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://karsonl.github.io" target="_blank">Karson.L</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AutoML/">AutoML</a><a class="post-meta__tags" href="/tags/pruning/">pruning</a><a class="post-meta__tags" href="/tags/model-compression/">model compression</a><a class="post-meta__tags" href="/tags/deep-learning/">deep learning</a></div><div class="post_share"><div class="social-share" data-image="https://img-blog.csdnimg.cn/20201224160209513.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/gh/overtrue/share.js@master/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/./imgs/reward/wechat-pay.jpg" target="_blank"><img class="post-qr-code-img" src="/./imgs/reward/wechat-pay.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/post/76d93c14.html"><img class="prev-cover" src="https://img-blog.csdnimg.cn/20201105161659183.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">A Knee_Guided Evolutionary Algorithm for Compressing Deep Neural Network （KGEA）解读</div></div></a></div><div class="next-post pull-right"><a href="/post/866b0930.html"><img class="next-cover" src="https://img-blog.csdnimg.cn/471ad4aa35ff41778d06c1501bf1e9de.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">sqlzoo 练习3——SELECT from Nobel</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/post/76d93c14.html" title="A Knee_Guided Evolutionary Algorithm for Compressing Deep Neural Network （KGEA）解读"><img class="cover" src="https://img-blog.csdnimg.cn/20201105161659183.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-05</div><div class="title">A Knee_Guided Evolutionary Algorithm for Compressing Deep Neural Network （KGEA）解读</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/./imgs/author/jide.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Karson.L</div><div class="author-info__description">小小程序员</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">10</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/KarsonL"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/KarsonL" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/1246737796@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">1.</span> <span class="toc-text">一、核心思想</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90"><span class="toc-number">2.</span> <span class="toc-text">二、问题分析</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E6%96%B9%E6%B3%95%E6%A1%86%E6%9E%B6"><span class="toc-number">3.</span> <span class="toc-text">三、方法框架</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1"><span class="toc-number">4.</span> <span class="toc-text">四、核心设计</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-%E5%8A%A8%E4%BD%9C%E8%AE%BE%E8%AE%A1"><span class="toc-number">4.1.</span> <span class="toc-text">4.1 动作设计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-%E7%8A%B6%E6%80%81%E8%AE%BE%E8%AE%A1"><span class="toc-number">4.2.</span> <span class="toc-text">4.2 状态设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-1-%E7%8A%B6%E6%80%81%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="toc-number">4.2.1.</span> <span class="toc-text">4.2.1 状态的计算</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3-%E5%A5%96%E5%8A%B1%E5%87%BD%E6%95%B0%E8%AE%BE%E8%AE%A1"><span class="toc-number">4.3.</span> <span class="toc-text">4.3 奖励函数设计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-4-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%AE%BE%E8%AE%A1"><span class="toc-number">4.4.</span> <span class="toc-text">4.4 损失函数设计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-5-%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="toc-number">4.5.</span> <span class="toc-text">4.5 算法流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-1-%E6%B5%81%E7%A8%8B"><span class="toc-number">4.5.1.</span> <span class="toc-text">4.5.1 流程</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E6%80%BB%E7%BB%93"><span class="toc-number">5.</span> <span class="toc-text">五、总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/post/560fed86.html" title="Docker 应用部署"><img src="/imgs/docker/docker.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Docker 应用部署"/></a><div class="content"><a class="title" href="/post/560fed86.html" title="Docker 应用部署">Docker 应用部署</a><time datetime="2022-06-18T11:08:56.869Z" title="发表于 2022-06-18 19:08:56">2022-06-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/817c7d82.html" title="Linux 常用命令"><img src="/./imgs/linux/linux.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux 常用命令"/></a><div class="content"><a class="title" href="/post/817c7d82.html" title="Linux 常用命令">Linux 常用命令</a><time datetime="2022-04-13T07:34:12.000Z" title="发表于 2022-04-13 15:34:12">2022-04-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/25e263b7.html" title="sqlzoo-练习5——SUM and COUNT"><img src="https://img-blog.csdnimg.cn/471ad4aa35ff41778d06c1501bf1e9de.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="sqlzoo-练习5——SUM and COUNT"/></a><div class="content"><a class="title" href="/post/25e263b7.html" title="sqlzoo-练习5——SUM and COUNT">sqlzoo-练习5——SUM and COUNT</a><time datetime="2021-07-28T07:07:26.000Z" title="发表于 2021-07-28 15:07:26">2021-07-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/57f1ab36.html" title="sqlzoo 练习 4——SELECT within SELECT"><img src="https://img-blog.csdnimg.cn/471ad4aa35ff41778d06c1501bf1e9de.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="sqlzoo 练习 4——SELECT within SELECT"/></a><div class="content"><a class="title" href="/post/57f1ab36.html" title="sqlzoo 练习 4——SELECT within SELECT">sqlzoo 练习 4——SELECT within SELECT</a><time datetime="2021-07-27T15:28:50.000Z" title="发表于 2021-07-27 23:28:50">2021-07-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/57684872.html" title="sqlzoo 练习1、2——SELECT from WORLD)"><img src="https://img-blog.csdnimg.cn/471ad4aa35ff41778d06c1501bf1e9de.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="sqlzoo 练习1、2——SELECT from WORLD)"/></a><div class="content"><a class="title" href="/post/57684872.html" title="sqlzoo 练习1、2——SELECT from WORLD)">sqlzoo 练习1、2——SELECT from WORLD)</a><time datetime="2021-07-27T12:25:53.000Z" title="发表于 2021-07-27 20:25:53">2021-07-27</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://img-blog.csdnimg.cn/20201224160209513.png')"><div id="footer-wrap"><div class="copyright">&copy;2022 By Karson.L</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Welcome to my blog!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (true){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>